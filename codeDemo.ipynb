{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codeDemo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgNc7WGIeZxB",
        "outputId": "e6b947e0-a34f-4a4c-f749-c1847432a8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gensim \n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import nltk\n",
        "import time\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from scipy import spatial\n",
        "from sklearn.cluster import KMeans\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "H6BybAdKefY0",
        "outputId": "167631f6-461c-45a9-e20b-acfae19fd98d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aac459f1-9d50-494c-961b-f7f03ea127f9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aac459f1-9d50-494c-961b-f7f03ea127f9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving toy_1000_trp.csv to toy_1000_trp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TrainModel(csv_document, csv_comment_column='body', outputname='outputModel', window = 4, minf=10, epochs=100, ndim=200, lemmatiseFirst = False, verbose = True):\n",
        "\t'''\n",
        "\tLoad the documents from csv_document and column csv_comment_column, trains a skipgram embedding model with given parameters and saves it in outputname.\n",
        "\tcsv_document <str> : path to reddit csv dataset\n",
        "\tcsv_comment_column <str> : column where comments are stored\n",
        "\toutputname <str> : output model name\n",
        "\twindow = 4, minf=10, epochs=100, ndim=200, lemmatiseFirst = False, tolower= True : Training and preprocessing parameters\n",
        "\t'''\n",
        "\n",
        "\tdef loadCSVAndPreprocess(path, column = 'body', nrowss=None, verbose = True):\n",
        "\t\t'''\n",
        "\t\tinput:\n",
        "\t\tpath <str> : path to csv file\n",
        "\t\tcolumn <str> : column with text\n",
        "\t\tnrowss <int> : number of rows to process, leave None if all\n",
        "\t\tverbose <True/False> : verbose output\n",
        "\t\ttolower <True/False> : transform all text to lowercase\n",
        "\t\treturns:\n",
        "\t\tlist of preprocessed sentences\n",
        "\t\t'''\n",
        "\t\ttrpCom = pd.read_csv(path, lineterminator='\\n', nrows=nrowss)\n",
        "\t\tdocuments = []\n",
        "\t\tfor i, row in enumerate(trpCom[column]):\n",
        "\t\t\t\n",
        "\n",
        "\t\t\tif i%500000 == 0 and verbose == True:\n",
        "\t\t\t\tprint('\\t...processing line {}'.format(i))\n",
        "\t\t\ttry:\n",
        "\t\t\t\tpp = gensim.utils.simple_preprocess (row)\n",
        "\t\t\t\tif(lemmatiseFirst == True):\n",
        "\t\t\t\t\tpp = [wordnet_lemmatizer.lemmatize(w, pos=\"n\") for w in pp]\n",
        "\t\t\t\tdocuments.append(pp)\n",
        "\t\t\texcept:\n",
        "\t\t\t\tif(verbose):\n",
        "\t\t\t\t\tprint('\\terror with row {}'.format(row))\n",
        "\t\tprint('Done reading all documents')\n",
        "\t\treturn documents\n",
        "\n",
        "\tdef trainWEModel(documents, outputfile, ndim, window, minfreq, epochss):\n",
        "\t\t'''\n",
        "\t\tdocuments list<str> : List of texts preprocessed\n",
        "\t\toutputfile <str> : final file will be saved in this path\n",
        "\t\tndim <int> : embedding dimensions\n",
        "\t\twindow <int> : window when training the model\n",
        "\t\tminfreq <int> : minimum frequency, words with less freq will be discarded\n",
        "\t\tepochss <int> : training epochs\n",
        "\t\t'''\n",
        "\t\tstarttime = time.time()\n",
        "\t\tprint('->->Starting training model {} with dimensions:{}, minf:{}, epochs:{}'.format(outputfile,ndim, minfreq, epochss))\n",
        "\t\tmodel = gensim.models.Word2Vec (documents, size=ndim, window=window, min_count=minfreq, workers=5)\n",
        "\t\tmodel.train(documents,total_examples=len(documents),epochs=epochss)\n",
        "\t\tmodel.save(outputfile)\n",
        "\t\tprint('->-> Model saved in {}'.format(outputfile))     \n",
        "\n",
        "     \n",
        "\tprint('->Starting with {} [{}], output {}, window {}, minf {}, epochs {}, ndim {}'.format(csv_document,csv_comment_column,outputname, window, minf, epochs, ndim))\n",
        "\tdocs = loadCSVAndPreprocess(csv_document, csv_comment_column, nrowss=None, verbose=verbose)\n",
        "\tstarttime = time.time()\n",
        "\tprint('-> Output will be saved in {}'.format(outputname))\n",
        "\ttrainWEModel(docs, outputname, ndim, window, minf, epochs)\n",
        "\tprint('-> Model creation ended in {} seconds'.format(time.time()-starttime))"
      ],
      "metadata": {
        "id": "KofO_dfkepBE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "def GetTopMostBiasedWords(modelpath, topk, c1, c2, pos = ['JJ','JJR','JJS'], verbose = True):\n",
        "\t'''\n",
        "\tmodelpath <str> : path to skipgram w2v model\n",
        "\ttopk <int> : topk words\n",
        "\tc1 list<str> : list of words for target set 1\n",
        "\tc2 list<str> : list of words for target set 2\n",
        "\tpos list<str> : List of parts of speech we are interested in analysing\n",
        "\tverbose <bool> : True/False\n",
        "\t'''\n",
        "\n",
        "\tdef calculateCentroid(model, words):\n",
        "\t\tembeddings = [np.array(model[w]) for w in words if w in model]\n",
        "\t\tcentroid = np.zeros(len(embeddings[0]))\n",
        "\t\tfor e in embeddings:\n",
        "\t\t\tcentroid += e\n",
        "\t\treturn centroid/len(embeddings)\n",
        "\n",
        "\tdef getCosineDistance(embedding1, embedding2):       \n",
        "\t\treturn spatial.distance.cosine(embedding1, embedding2)\n",
        "\n",
        "\n",
        "\t#select the interesting subset of words based on pos\n",
        "\tmodel = Word2Vec.load(modelpath)\n",
        "\twords_sorted = sorted( [(k,v.index, v.count) for (k,v) in model.wv.vocab.items()] ,  key=lambda x: x[1], reverse=False)\n",
        "\twords = [w for w in words_sorted if nltk.pos_tag([w[0]])[0][1] in pos]\n",
        "\n",
        "\tif len(c1) < 1 or len(c2) < 1 or len(words) < 1:\n",
        "\t\tprint('[!] Not enough word concepts to perform the experiment')\n",
        "\t\treturn None\n",
        "\n",
        "\tcentroid1, centroid2 = calculateCentroid(model, c1),calculateCentroid(model, c2)\n",
        "\twinfo = []\n",
        "\tfor i, w in enumerate(words):\n",
        "\t\tword = w[0]\n",
        "\t\tfreq = w[2]\n",
        "\t\trank = w[1]\n",
        "\t\tpos = nltk.pos_tag([word])[0][1]\n",
        "\t\twv = model[word]\n",
        "\t\tsent = sid.polarity_scores(word)['compound']\n",
        "\t\t#estimate cosinedistance diff\n",
        "\t\td1 = getCosineDistance(centroid1, wv)\n",
        "\t\td2 = getCosineDistance(centroid2, wv)\n",
        "\t\tbias = d2-d1\n",
        "\n",
        "\t\twinfo.append({'word':word, 'bias':bias, 'freq':freq, 'pos':pos, 'wv':wv, 'rank':rank, 'sent':sent} )\n",
        "\n",
        "\t\tif(i%100 == 0 and verbose == True):\n",
        "\t\t\tprint('...'+str(i), end=\"\")\n",
        "\n",
        "\t#Get max and min topk biased words...\n",
        "\tbiasc1 = sorted( winfo, key=lambda x:x['bias'], reverse=True )[:min(len(winfo), topk)]\n",
        "\tbiasc2 = sorted( winfo, key=lambda x:x['bias'], reverse=False )[:min(len(winfo), topk)]\n",
        "    #move the ts2 bias to the positive space\n",
        "\tfor w2 in biasc2:\n",
        "\t\tw2['bias'] = w2['bias']*-1\n",
        "    \n",
        "\treturn [biasc1, biasc2]"
      ],
      "metadata": {
        "id": "uxarVz3TfIko"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Cluster(biasc1, biasc2, r, repeatk, verbose = True):\n",
        "\t'''\n",
        "\tbiasc1 list<words> : List of words biased towards target concept1 as returned by GetTopMostBiasedWords\n",
        "\tbiasc2 list<words> : List of words biased towards target concept2 as returned by GetTopMostBiasedWords\n",
        "\tr <int> : reduction factor used to determine k for the kmeans; k = r * len(voc) \n",
        "\trepeatk <int> : Number of Clustering to perform only to keep the partition with best intrasim\n",
        "\t'''\n",
        "\tdef getCosineDistance(embedding1, embedding2): \n",
        "\t\treturn spatial.distance.cosine(embedding1, embedding2)\n",
        "\tdef getIntraSim(partition):\n",
        "\t\tiS = 0\n",
        "\t\tfor cluster in partition:\n",
        "\t\t\tiS += getIntraSimCluster(cluster)\n",
        "\t\treturn iS/len(partition)\n",
        "\tdef getIntraSimCluster(cluster):\n",
        "\t\tif(len(cluster)==1):\n",
        "\t\t\treturn 0\n",
        "\t\tsim = 0; c = 0\n",
        "\t\tfor i in range(len(cluster)):\n",
        "\t\t\tw1 = cluster[i]['wv']\n",
        "\t\t\tfor j in range(i+1, len(cluster)):\n",
        "\t\t\t\tw2 = cluster[j]['wv']\n",
        "\t\t\t\tsim+= 1-getCosineDistance(w1,w2)\n",
        "\t\t\t\tc+=1\n",
        "\t\treturn sim/c\n",
        "\tdef createPartition(embeddings, biasw, k):\n",
        "\t\tpreds = KMeans (n_clusters=k).fit_predict(embeddings)\n",
        "\t\t#first create the proper clusters, then estiamte avg intra sim\n",
        "\t\tall_clusters = []\n",
        "\t\tfor i in range(0, k):\n",
        "\t\t\tclust = []\n",
        "\t\t\tindexes = np.where(preds == i)[0]\n",
        "\t\t\tfor idx in indexes:\n",
        "\t\t\t\tclust.append(biasw[idx])\n",
        "\t\t\tall_clusters.append(clust)\n",
        "\t\tscore = getIntraSim(all_clusters)\n",
        "\t\treturn [score, all_clusters]\n",
        "\n",
        "\n",
        "\tk = int(r * (len(biasc1)+len(biasc2))/2)\n",
        "\temb1, emb2  = [w['wv'] for w in biasc1], [w['wv'] for w in biasc2]\n",
        "\tmis1, mis2 = [0,[]], [0,[]]\t#here we will save partitions with max sim for both target sets\n",
        "\tfor run in range(repeatk):\n",
        "\t\tp1 = createPartition(emb1, biasc1, k)\n",
        "\t\tif(p1[0] > mis1[0]):\n",
        "\t\t\tmis1 = p1\n",
        "\t\tp2 = createPartition(emb2, biasc2, k)\n",
        "\t\tif(p2[0] > mis2[0]):\n",
        "\t\t\tmis2 = p2\n",
        "\t\tif(verbose == True):\n",
        "\t\t\tprint('New partition for ts1, intrasim: ', p1[0])\n",
        "\t\t\tprint('New partition for ts2, intrasim: ', p2[0])\n",
        "\n",
        "\tprint('[*] Intrasim of best partition found for ts1, ', mis1[0])\n",
        "\tprint('[*] Intrasim of best partition found for ts2, ', mis2[0])\n",
        "\treturn [mis1[1], mis2[1]]\n",
        "\t\t"
      ],
      "metadata": {
        "id": "q5iPajfhfMtA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Train an embeddings model using word2vec with different parameters.\n",
        "'''\n",
        "\n",
        "\n",
        "trainingSetups = [\n",
        "    {'csvfile': \"toy_1000_trp.csv\", 'outputFile': 'Models', 'w':4, 'minf': 10, 'epochs':10 ,'ndim':200},\n",
        "    #....\n",
        "]\n",
        "\n",
        "for setup in trainingSetups:\n",
        "    TrainModel(setup['csvfile'], \n",
        "           'body',\n",
        "           outputname = setup['outputFile'],\n",
        "           window = setup['w'],\n",
        "           minf = setup['minf'],\n",
        "           epochs = setup['epochs'],\n",
        "           ndim = setup['ndim'],\n",
        "           verbose = False\n",
        "           )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtsxJp55fkf1",
        "outputId": "2443006f-93fd-42d0-c79c-a875e750bec8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "->Starting with toy_1000_trp.csv [body], output Models, window 4, minf 10, epochs 10, ndim 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DtypeWarning: Columns (1,3,4) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done reading all documents\n",
            "-> Output will be saved in Models\n",
            "->->Starting training model Models with dimensions:200, minf:10, epochs:10\n",
            "->-> Model saved in Models\n",
            "-> Model creation ended in 254.67558908462524 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "List of target sets used in this work, replace them in GetTopMostBiasedWords to obtain different sets of biases\n",
        "or create your own target sets to represent a concept!\n",
        "'''\n",
        "\n",
        "women=[\"sister\" , \"female\" , \"woman\" , \"girl\" , \"daughter\" , \"she\" , \"hers\" , \"her\"]\n",
        "men=[\"brother\" , \"male\" , \"man\" , \"boy\" , \"son\" , \"he\" , \"his\" , \"him\"]  \n",
        "\n",
        "islam = [\"allah\", \"ramadan\", \"turban\", \"emir\", \"salaam\", \"sunni\", \"koran\", \"imam\", \"sultan\", \"prophet\", \"veil\", \"ayatollah\", \"shiite\", \"mosque\", \"islam\", \"sheik\", \"muslim\", \"muhammad\"]\n",
        "christian = [\"baptism\", \"messiah\", \"catholicism\", \"resurrection\", \"christianity\", \"salvation\", \"protestant\", \"gospel\", \"trinity\", \"jesus\", \"christ\", \"christian\", \"cross\", \"catholic\", \"church\"]\n",
        "\n",
        "white_names = [\"harris\", \"nelson\", \"robinson\", \"thompson\", \"moore\", \"wright\", \"anderson\", \"clark\", \"jackson\", \"taylor\", \"scott\", \"davis\", \"allen\", \"adams\", \"lewis\", \"williams\", \"jones\", \"wilson\", \"martin\", \"johnson\"]\n",
        "hispanic_names= [\"ruiz\", \"alvarez\", \"vargas\", \"castillo\", \"gomez\", \"soto\", \"gonzalez\", \"sanchez\", \"rivera\", \"mendoza\", \"martinez\", \"torres\", \"rodriguez\", \"perez\", \"lopez\", \"medina\", \"diaz\", \"garcia\", \"castro\", \"cruz\"]\n"
      ],
      "metadata": {
        "id": "MMfzkzelfpbH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Call GetTopMostBiasedWords to obtain a list of the topk words with POS = ['JJ','JJR','JJS'] \n",
        "most biased towards women and men target sets in the model.\n",
        "\n",
        "The function returns two word lists, b1 and b2, which contain all words from the embedding model most biased towards\n",
        "women (b1) and men (b2). \n",
        "'''\n",
        "\n",
        "modelpath = 'Models'  #add your model here!\n",
        "[b1,b2] = GetTopMostBiasedWords(\n",
        "        modelpath,\n",
        "        300,\n",
        "        women,\n",
        "        men,\n",
        "        ['JJ','JJR','JJS'],\n",
        "        True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv-gqQpwfsKZ",
        "outputId": "94a87dd9-72ae-46e2-b2ce-e462f877355d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...0...100...200...300...400...500...600...700...800...900"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "List all topk biased words\n",
        "'''\n",
        "print('biased towards ', women)\n",
        "print( [b['word'] for b in b1[:30]] )\n",
        "print('biased towards ', men)\n",
        "print( [b['word'] for b in b2[:30]] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJewkwg-fw4l",
        "outputId": "b925002a-65c7-4288-89be-61c5f724a136"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "biased towards  ['sister', 'female', 'woman', 'girl', 'daughter', 'she', 'hers', 'her']\n",
            "['available', 'formal', 'mutual', 'second', 'third', 'small', 'okcupid', 'comfortable', 'free', 'viable', 'informal', 'neutral', 'common', 'continued', 'inexpensive', 'arrive', 'variable', 'suitable', 'compatible', 'unplanned', 'geographical', 'single', 'exclusive', 'wide', 'enjoyable', 'organic', 'specific', 'instantaneous', 'chic', 'ready']\n",
            "biased towards  ['brother', 'male', 'man', 'boy', 'son', 'he', 'his', 'him']\n",
            "['homosexual', 'ouch', 'unfriended', 'lest', 'respectable', 'unapologetic', 'underwear', 'overall', 'glorious', 'inexperienced', 'poor', 'enable', 'heterosexual', 'dependable', 'pathetic', 'argumentative', 'abusive', 'total', 'abrasive', 'lustful', 'nasty', 'sensitive', 'hippy', 'vicious', 'obsessive', 'bearable', 'metaphorical', 'pedantic', 'psychotic', 'delighted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Every word returned by GetTopMostBiasedWords contains the next attributes:\n",
        "word : Word \n",
        "bias : Bias strength towards target set 1 (in this example) when compared to target set 2\n",
        "freq : Frequency of word in the vocabulary of the model\n",
        "pos  : Part of speech as determined by NLTK\n",
        "wv   : Embedding of the word, used for clustering later\n",
        "rank : Frequency ranking of the word in model's vocabulary\n",
        "sent : Sentiment of word [-1,1], as determined by nltk.sentiment.vader\n",
        "\n",
        "Here we show the firt word biased towards women in the toy dataset\n",
        "'''\n",
        "b1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZqlxGNafzqC",
        "outputId": "2e7a6081-7976-4a0f-f983-61a25c4a6bc4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bias': 0.17276236633485464,\n",
              " 'freq': 1251,\n",
              " 'pos': 'JJ',\n",
              " 'rank': 874,\n",
              " 'sent': 0.0,\n",
              " 'word': 'available',\n",
              " 'wv': array([ 0.07670205, -0.6021249 , -0.53167796, -1.3170775 ,  0.7293684 ,\n",
              "         1.6956341 ,  1.2280496 ,  0.21225786, -0.6355291 ,  2.3789127 ,\n",
              "         1.5463523 ,  0.99710315, -0.43532225, -0.04214282,  0.09582525,\n",
              "         1.2594104 ,  1.6384648 , -1.093577  ,  0.2618014 , -0.2249213 ,\n",
              "         1.3811804 , -0.7382754 , -0.6766405 ,  1.7232198 , -2.1547043 ,\n",
              "        -0.5104562 , -0.19955562, -0.78912383, -0.7859196 , -0.15164861,\n",
              "        -0.7796448 , -0.34839168, -1.4293412 ,  0.88701063,  0.8642951 ,\n",
              "         1.5783696 , -0.7250896 , -0.9839688 ,  0.20061877,  1.8219093 ,\n",
              "         1.4210857 ,  0.89474654, -1.2435374 ,  1.9881847 , -0.69109607,\n",
              "         1.1907544 ,  0.5251658 , -2.0476773 ,  2.3237197 , -0.688011  ,\n",
              "         2.0926065 , -1.6444218 ,  0.25367507,  0.590795  ,  0.8323878 ,\n",
              "        -0.20088811,  0.7689315 , -1.6661421 , -0.78327775, -0.09116092,\n",
              "         0.36929655, -1.3279542 , -0.3064208 , -0.7918662 ,  0.458287  ,\n",
              "        -0.0053978 ,  2.0049334 ,  0.69978064,  1.4226352 ,  1.6402974 ,\n",
              "        -0.8547786 ,  0.6013007 ,  0.5483868 ,  1.1199379 ,  0.40858138,\n",
              "        -2.6586096 ,  0.40720642, -1.4160933 , -0.06864692, -0.9310491 ,\n",
              "        -0.12004114,  0.32518253,  0.03043952,  0.69655263, -0.9943979 ,\n",
              "        -1.3112166 , -0.24122022,  2.4674416 ,  0.13146074, -0.8433094 ,\n",
              "         0.7825507 , -1.0915219 , -0.26913157, -0.76459116, -1.2421737 ,\n",
              "        -0.7285968 ,  0.5574813 ,  0.47793573,  1.2068541 , -0.98619384,\n",
              "        -1.5172898 ,  1.9101042 ,  0.00324544,  0.62748116, -0.2955212 ,\n",
              "        -1.5316361 , -2.0210185 ,  1.2942703 ,  0.1146436 ,  1.1341445 ,\n",
              "         1.8520807 , -0.29770917,  0.7683648 ,  0.97883785, -1.3243744 ,\n",
              "         0.7774318 ,  0.11117517, -0.10093034,  0.49766573,  0.11408045,\n",
              "         1.5052037 ,  1.0198734 ,  0.35919404, -1.3405383 , -1.2752856 ,\n",
              "         0.23599407, -0.14794537, -0.03876571,  1.0158556 , -1.8203344 ,\n",
              "        -0.27299517, -1.4228449 , -0.04566368,  0.23833019, -0.3012547 ,\n",
              "         0.9331893 ,  1.3091486 ,  0.9177938 ,  0.23197089, -1.2077852 ,\n",
              "        -0.34095863,  1.216948  , -0.4886159 , -0.3215779 , -1.4188478 ,\n",
              "        -0.06319958,  1.8434267 , -0.3013033 , -1.1876526 ,  1.24325   ,\n",
              "         0.04941435, -0.8026366 , -0.8619765 , -0.9443838 , -1.377516  ,\n",
              "        -0.42756853, -1.2102662 , -0.09794016,  0.3645983 ,  0.92406344,\n",
              "        -0.5623199 , -0.18519786,  2.0752864 , -0.06539829,  1.6229132 ,\n",
              "         0.46851945, -1.3063399 , -0.79475886, -2.2597017 ,  1.0541409 ,\n",
              "        -1.1518763 , -0.24736764, -2.119608  , -2.1305318 ,  0.37472337,\n",
              "        -0.37999484, -2.7388544 , -1.2108477 ,  0.5645996 ,  0.01401616,\n",
              "        -1.7006088 ,  0.3187367 ,  0.30662483,  0.25890648, -0.4792888 ,\n",
              "         1.0755535 , -0.35563838, -1.6825315 ,  0.49521795, -0.01808773,\n",
              "         0.56029874, -0.28613895,  0.5416219 , -0.7015309 ,  0.6866007 ,\n",
              "         0.36723956, -2.1023698 , -1.5006347 , -0.77898055,  0.04502498],\n",
              "       dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here we show the firt word biased towards men in the toy dataset\n",
        "'''\n",
        "b2[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYVmCIPif1if",
        "outputId": "fb4068e2-4969-4115-c692-5846310bbceb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bias': 0.16837280946765665,\n",
              " 'freq': 13,\n",
              " 'pos': 'JJ',\n",
              " 'rank': 11468,\n",
              " 'sent': 0.0,\n",
              " 'word': 'unapologetic',\n",
              " 'wv': array([ 0.06084435, -0.01344283, -0.28146487, -0.07252999, -0.01667341,\n",
              "        -0.03266788,  0.01186611, -0.04430195,  0.17923376, -0.14431918,\n",
              "         0.1304737 , -0.02197906, -0.02756139,  0.1220159 , -0.07651004,\n",
              "         0.24718468,  0.07713524,  0.27304015, -0.14844182, -0.37265205,\n",
              "         0.18438892,  0.07987133, -0.05941497,  0.04338085, -0.1629849 ,\n",
              "         0.02878095,  0.03314534, -0.09514685,  0.03163952, -0.3032108 ,\n",
              "         0.14570816,  0.0770566 ,  0.41796938, -0.00723047,  0.13007405,\n",
              "         0.13973737, -0.00296919, -0.19125172, -0.06367651,  0.06598613,\n",
              "         0.2773335 , -0.21882269, -0.03792665, -0.09654344, -0.06552457,\n",
              "        -0.24015099, -0.32271338, -0.13033666,  0.03015729, -0.09921532,\n",
              "         0.05086885,  0.2273484 , -0.25470018,  0.21543704, -0.22669107,\n",
              "         0.12643558, -0.19124629,  0.05064442,  0.17519145,  0.10620119,\n",
              "        -0.22924909, -0.1615418 ,  0.2742101 ,  0.0497397 , -0.07691292,\n",
              "         0.02675419, -0.15303676,  0.04248274, -0.03043728,  0.12784246,\n",
              "         0.06389959, -0.06494915,  0.07211755,  0.30215582, -0.39572927,\n",
              "         0.00515765, -0.21158312, -0.04330743, -0.12271117, -0.12974931,\n",
              "        -0.01079104, -0.11105064,  0.15058106,  0.02971395, -0.06994035,\n",
              "         0.23876333, -0.03811259,  0.07405483,  0.04096346,  0.13410112,\n",
              "         0.07832879,  0.21161719,  0.09485443, -0.215887  , -0.02806056,\n",
              "        -0.11889838,  0.19990039,  0.11081807, -0.26337108,  0.10727266,\n",
              "         0.20659243,  0.04391896, -0.02616495,  0.30798662, -0.03239728,\n",
              "        -0.03656534, -0.17808846,  0.08618383,  0.18785426, -0.0531256 ,\n",
              "        -0.03943902, -0.06506557,  0.07071069, -0.21211109,  0.10960421,\n",
              "        -0.01707724, -0.3378814 ,  0.11791117,  0.00322996,  0.11770852,\n",
              "        -0.32952407,  0.03228372,  0.49856362,  0.07197767,  0.06139065,\n",
              "        -0.21650028,  0.02952668,  0.08786206,  0.08929575, -0.07984343,\n",
              "        -0.1237818 ,  0.0335598 ,  0.0019534 , -0.22671574,  0.119523  ,\n",
              "        -0.14873329, -0.13605955, -0.22501093,  0.02337058, -0.39188546,\n",
              "        -0.03529726,  0.31737483, -0.23497094, -0.00490575,  0.09110742,\n",
              "         0.3082047 , -0.01587185,  0.10135712, -0.06908767,  0.38179985,\n",
              "         0.05888014, -0.2631864 ,  0.18130848,  0.18837349,  0.24395794,\n",
              "         0.08486266,  0.06504887,  0.18801005, -0.11413742, -0.04531289,\n",
              "         0.02463871, -0.16262141,  0.08777488,  0.1640729 ,  0.14568375,\n",
              "        -0.13857041,  0.09029312, -0.1699864 ,  0.11199223,  0.07092562,\n",
              "        -0.08192257,  0.0416603 ,  0.21362133,  0.09667336, -0.12057166,\n",
              "        -0.09096629,  0.0978791 , -0.24317569, -0.06057164,  0.12632819,\n",
              "        -0.21873638, -0.07549423,  0.04320763,  0.23053655, -0.0396794 ,\n",
              "        -0.00345769, -0.14291   ,  0.16538286, -0.09126899, -0.40216315,\n",
              "        -0.0222402 , -0.42095873,  0.20264852, -0.07739768,  0.01946043,\n",
              "        -0.24472073,  0.19530526,  0.16762537,  0.02406488, -0.02306139],\n",
              "       dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Cluster words into concepts by leveragin their embedding distributions, where\n",
        "b1 : list of biased words towards target set 1\n",
        "b2 : list of biased words towards target set 2\n",
        "r  : r parameter for k-means clustering, where k = r*len(b)\n",
        "100: partition repetitoins for k-means, keeping the partition with best intrasim\n",
        "\n",
        "The function returns:\n",
        "List of clusters in a partition and words clustered in each cluster, for both target sets (cl1, cl2).\n",
        "'''\n",
        "[cl1,cl2] = Cluster(b1,b2, 0.15, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sExnfNY7f4X0",
        "outputId": "9f027e8f-6873-4dec-e2b5-2808d4e19ff5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New partition for ts1, intrasim:  0.13540145996845449\n",
            "New partition for ts2, intrasim:  0.08075208835402477\n",
            "New partition for ts1, intrasim:  0.17872933043384304\n",
            "New partition for ts2, intrasim:  0.10049539933916939\n",
            "New partition for ts1, intrasim:  0.12282290394118611\n",
            "New partition for ts2, intrasim:  0.078077233342781\n",
            "New partition for ts1, intrasim:  0.14728380905850963\n",
            "New partition for ts2, intrasim:  0.06977397075713551\n",
            "New partition for ts1, intrasim:  0.15352796818025846\n",
            "New partition for ts2, intrasim:  0.08254230192983798\n",
            "New partition for ts1, intrasim:  0.13858360628881414\n",
            "New partition for ts2, intrasim:  0.09808052887733464\n",
            "New partition for ts1, intrasim:  0.1368876396117701\n",
            "New partition for ts2, intrasim:  0.07512129606351435\n",
            "New partition for ts1, intrasim:  0.14293421566351894\n",
            "New partition for ts2, intrasim:  0.08103004605536236\n",
            "New partition for ts1, intrasim:  0.14560969713896535\n",
            "New partition for ts2, intrasim:  0.09812389924174884\n",
            "New partition for ts1, intrasim:  0.1578951011196674\n",
            "New partition for ts2, intrasim:  0.07522896897365915\n",
            "New partition for ts1, intrasim:  0.15063214839707445\n",
            "New partition for ts2, intrasim:  0.06483917195779\n",
            "New partition for ts1, intrasim:  0.1283245389871111\n",
            "New partition for ts2, intrasim:  0.14066245230449637\n",
            "New partition for ts1, intrasim:  0.14613617723824116\n",
            "New partition for ts2, intrasim:  0.08989482884923948\n",
            "New partition for ts1, intrasim:  0.14006637474675546\n",
            "New partition for ts2, intrasim:  0.06328032989852231\n",
            "New partition for ts1, intrasim:  0.13409211556089978\n",
            "New partition for ts2, intrasim:  0.0919076530000325\n",
            "New partition for ts1, intrasim:  0.15225228514836558\n",
            "New partition for ts2, intrasim:  0.09879644080025789\n",
            "New partition for ts1, intrasim:  0.14997824291213388\n",
            "New partition for ts2, intrasim:  0.08385032652788413\n",
            "New partition for ts1, intrasim:  0.12420045726242464\n",
            "New partition for ts2, intrasim:  0.08483242034181235\n",
            "New partition for ts1, intrasim:  0.14608859646134584\n",
            "New partition for ts2, intrasim:  0.07753298961082425\n",
            "New partition for ts1, intrasim:  0.14354819595302754\n",
            "New partition for ts2, intrasim:  0.049705758508907384\n",
            "New partition for ts1, intrasim:  0.12997930996235202\n",
            "New partition for ts2, intrasim:  0.07220430649446359\n",
            "New partition for ts1, intrasim:  0.14954683090936474\n",
            "New partition for ts2, intrasim:  0.08603748561535379\n",
            "New partition for ts1, intrasim:  0.16554245818297272\n",
            "New partition for ts2, intrasim:  0.08099627850057227\n",
            "New partition for ts1, intrasim:  0.11479724485748691\n",
            "New partition for ts2, intrasim:  0.0854810611689363\n",
            "New partition for ts1, intrasim:  0.12788573545322804\n",
            "New partition for ts2, intrasim:  0.09682301245685163\n",
            "New partition for ts1, intrasim:  0.14147823667158008\n",
            "New partition for ts2, intrasim:  0.07160655722110065\n",
            "New partition for ts1, intrasim:  0.13359854966963733\n",
            "New partition for ts2, intrasim:  0.11117246349604029\n",
            "New partition for ts1, intrasim:  0.1382146570149779\n",
            "New partition for ts2, intrasim:  0.10096299049268648\n",
            "New partition for ts1, intrasim:  0.1204245199069474\n",
            "New partition for ts2, intrasim:  0.060899175018872105\n",
            "New partition for ts1, intrasim:  0.16754943393649\n",
            "New partition for ts2, intrasim:  0.06731930645425292\n",
            "New partition for ts1, intrasim:  0.14034431899939648\n",
            "New partition for ts2, intrasim:  0.09405543514663138\n",
            "New partition for ts1, intrasim:  0.11414442763136232\n",
            "New partition for ts2, intrasim:  0.09232409943823257\n",
            "New partition for ts1, intrasim:  0.10496372862923763\n",
            "New partition for ts2, intrasim:  0.11171242022836428\n",
            "New partition for ts1, intrasim:  0.16581512434944914\n",
            "New partition for ts2, intrasim:  0.09639326334694162\n",
            "New partition for ts1, intrasim:  0.14393720406217314\n",
            "New partition for ts2, intrasim:  0.06703841914334509\n",
            "New partition for ts1, intrasim:  0.12912824849455548\n",
            "New partition for ts2, intrasim:  0.07471262830808932\n",
            "New partition for ts1, intrasim:  0.15864016823295976\n",
            "New partition for ts2, intrasim:  0.10940267133956866\n",
            "New partition for ts1, intrasim:  0.15678006935318678\n",
            "New partition for ts2, intrasim:  0.05311251334798583\n",
            "New partition for ts1, intrasim:  0.13416810632255521\n",
            "New partition for ts2, intrasim:  0.07351592586306185\n",
            "New partition for ts1, intrasim:  0.13990441733251777\n",
            "New partition for ts2, intrasim:  0.10666438334121688\n",
            "New partition for ts1, intrasim:  0.13958841680078332\n",
            "New partition for ts2, intrasim:  0.05467331445261495\n",
            "New partition for ts1, intrasim:  0.12385333374542182\n",
            "New partition for ts2, intrasim:  0.06723859538756745\n",
            "New partition for ts1, intrasim:  0.11819746694936634\n",
            "New partition for ts2, intrasim:  0.058024585037002724\n",
            "New partition for ts1, intrasim:  0.1292474237716276\n",
            "New partition for ts2, intrasim:  0.07220844323037515\n",
            "New partition for ts1, intrasim:  0.14298601118626889\n",
            "New partition for ts2, intrasim:  0.061235698423642286\n",
            "New partition for ts1, intrasim:  0.16050021718246693\n",
            "New partition for ts2, intrasim:  0.0994291693052823\n",
            "New partition for ts1, intrasim:  0.14633597512141996\n",
            "New partition for ts2, intrasim:  0.10601683255830897\n",
            "New partition for ts1, intrasim:  0.14840479984524757\n",
            "New partition for ts2, intrasim:  0.06808202509678693\n",
            "New partition for ts1, intrasim:  0.15642750510327497\n",
            "New partition for ts2, intrasim:  0.06884226812428394\n",
            "New partition for ts1, intrasim:  0.14665223592925727\n",
            "New partition for ts2, intrasim:  0.10177426574360303\n",
            "New partition for ts1, intrasim:  0.14216421028787968\n",
            "New partition for ts2, intrasim:  0.10247106095871499\n",
            "New partition for ts1, intrasim:  0.16454858730468694\n",
            "New partition for ts2, intrasim:  0.11267961162674034\n",
            "New partition for ts1, intrasim:  0.13901993210511884\n",
            "New partition for ts2, intrasim:  0.0880673442092336\n",
            "New partition for ts1, intrasim:  0.14278351814603046\n",
            "New partition for ts2, intrasim:  0.069930385697775\n",
            "New partition for ts1, intrasim:  0.13439369977796214\n",
            "New partition for ts2, intrasim:  0.11665559028292864\n",
            "New partition for ts1, intrasim:  0.13282622910517997\n",
            "New partition for ts2, intrasim:  0.11969669497487435\n",
            "New partition for ts1, intrasim:  0.14813485738515905\n",
            "New partition for ts2, intrasim:  0.0516023187194164\n",
            "New partition for ts1, intrasim:  0.16548186725794478\n",
            "New partition for ts2, intrasim:  0.09506944478354758\n",
            "New partition for ts1, intrasim:  0.14454781046692908\n",
            "New partition for ts2, intrasim:  0.10628789784863636\n",
            "New partition for ts1, intrasim:  0.1291660280554126\n",
            "New partition for ts2, intrasim:  0.08282829512872457\n",
            "New partition for ts1, intrasim:  0.16613440020745\n",
            "New partition for ts2, intrasim:  0.07978626852999199\n",
            "New partition for ts1, intrasim:  0.157942794778735\n",
            "New partition for ts2, intrasim:  0.06536599752207409\n",
            "New partition for ts1, intrasim:  0.16853767463428365\n",
            "New partition for ts2, intrasim:  0.09740129007549746\n",
            "New partition for ts1, intrasim:  0.13456906145377842\n",
            "New partition for ts2, intrasim:  0.09816580408514608\n",
            "New partition for ts1, intrasim:  0.1307645897033655\n",
            "New partition for ts2, intrasim:  0.08430171992054945\n",
            "New partition for ts1, intrasim:  0.12641174325715884\n",
            "New partition for ts2, intrasim:  0.10403932419520871\n",
            "New partition for ts1, intrasim:  0.16079267355000781\n",
            "New partition for ts2, intrasim:  0.07364925321841738\n",
            "New partition for ts1, intrasim:  0.13166925387336506\n",
            "New partition for ts2, intrasim:  0.10491213994490536\n",
            "New partition for ts1, intrasim:  0.15751464924633954\n",
            "New partition for ts2, intrasim:  0.0950868581468555\n",
            "New partition for ts1, intrasim:  0.12773635999916408\n",
            "New partition for ts2, intrasim:  0.1009241606974513\n",
            "New partition for ts1, intrasim:  0.1376236864574608\n",
            "New partition for ts2, intrasim:  0.0776009854241737\n",
            "New partition for ts1, intrasim:  0.1274041519743865\n",
            "New partition for ts2, intrasim:  0.09368785742179671\n",
            "New partition for ts1, intrasim:  0.14389029225575664\n",
            "New partition for ts2, intrasim:  0.1045264878202684\n",
            "New partition for ts1, intrasim:  0.17909741732878126\n",
            "New partition for ts2, intrasim:  0.11303167042232028\n",
            "New partition for ts1, intrasim:  0.11906859659564632\n",
            "New partition for ts2, intrasim:  0.10676907708749347\n",
            "New partition for ts1, intrasim:  0.13772601624373268\n",
            "New partition for ts2, intrasim:  0.06013611433660425\n",
            "New partition for ts1, intrasim:  0.14244780513135546\n",
            "New partition for ts2, intrasim:  0.08372561466162551\n",
            "New partition for ts1, intrasim:  0.1481533449832264\n",
            "New partition for ts2, intrasim:  0.05597913934383837\n",
            "New partition for ts1, intrasim:  0.13489852411462286\n",
            "New partition for ts2, intrasim:  0.07061658106245243\n",
            "New partition for ts1, intrasim:  0.13613733250553173\n",
            "New partition for ts2, intrasim:  0.07320636779002081\n",
            "New partition for ts1, intrasim:  0.15955346418494123\n",
            "New partition for ts2, intrasim:  0.09264517332019015\n",
            "New partition for ts1, intrasim:  0.15220220374408241\n",
            "New partition for ts2, intrasim:  0.07907608020140787\n",
            "New partition for ts1, intrasim:  0.15894420637415038\n",
            "New partition for ts2, intrasim:  0.06796363330513817\n",
            "New partition for ts1, intrasim:  0.15705506910120737\n",
            "New partition for ts2, intrasim:  0.08865834149607674\n",
            "New partition for ts1, intrasim:  0.16981326215914566\n",
            "New partition for ts2, intrasim:  0.11372653521708367\n",
            "New partition for ts1, intrasim:  0.17673756290338022\n",
            "New partition for ts2, intrasim:  0.10340802352303376\n",
            "New partition for ts1, intrasim:  0.10361008768638807\n",
            "New partition for ts2, intrasim:  0.10536278298787237\n",
            "New partition for ts1, intrasim:  0.14041676356703237\n",
            "New partition for ts2, intrasim:  0.06840699132124722\n",
            "New partition for ts1, intrasim:  0.12107803762600348\n",
            "New partition for ts2, intrasim:  0.08987203693542113\n",
            "New partition for ts1, intrasim:  0.14917254434295996\n",
            "New partition for ts2, intrasim:  0.08361693493917953\n",
            "New partition for ts1, intrasim:  0.1412970353229287\n",
            "New partition for ts2, intrasim:  0.0824790474254007\n",
            "New partition for ts1, intrasim:  0.1295976936823347\n",
            "New partition for ts2, intrasim:  0.08731853205486383\n",
            "New partition for ts1, intrasim:  0.13711725212544643\n",
            "New partition for ts2, intrasim:  0.07653209247238536\n",
            "New partition for ts1, intrasim:  0.15248126820886726\n",
            "New partition for ts2, intrasim:  0.09698587672520695\n",
            "New partition for ts1, intrasim:  0.15919947853451236\n",
            "New partition for ts2, intrasim:  0.06127293293608996\n",
            "New partition for ts1, intrasim:  0.1555020130848391\n",
            "New partition for ts2, intrasim:  0.10452561843801832\n",
            "New partition for ts1, intrasim:  0.15434044359469737\n",
            "New partition for ts2, intrasim:  0.06480623008750802\n",
            "New partition for ts1, intrasim:  0.12835614211481752\n",
            "New partition for ts2, intrasim:  0.07248060617958335\n",
            "New partition for ts1, intrasim:  0.13087601348766648\n",
            "New partition for ts2, intrasim:  0.08318207917019071\n",
            "New partition for ts1, intrasim:  0.11764641006608824\n",
            "New partition for ts2, intrasim:  0.06134297616604491\n",
            "[*] Intrasim of best partition found for ts1,  0.17909741732878126\n",
            "[*] Intrasim of best partition found for ts2,  0.14066245230449637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Exploring the conceptual biases from partition biased towards ts1, only printing the words in each cluster.\n",
        "'''\n",
        "#conceptual biases for target set 1\n",
        "print(len(cl1))\n",
        "for cluster in cl1:\n",
        "    print( [k['word'] for k in cluster] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh2-zNg0f7_t",
        "outputId": "a2ceeff1-6f97-47cf-a2df-996e681bd57e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "['okcupid', 'senior', 'native', 'english', 'original']\n",
            "['available', 'suitable', 'single', 'potential', 'attractive', 'desirable']\n",
            "['uncomfortable']\n",
            "['viable', 'informal', 'continued', 'variable', 'unplanned', 'geographical', 'organic', 'instantaneous', 'chic', 'earliest', 'actual', 'individual', 'noncommittal', 'fourth', 'innocuous', 'highest', 'plausible', 'unexpected', 'virtual', 'ethical', 'immaterial', 'visible', 'accessible', 'probable', 'weakest', 'arbitrary', 'unrelated', 'incompatible', 'ritual', 'genetic', 'noble', 'hypothetical', 'tangible', 'substantive', 'nonsexual', 'controversial', 'unnatural', 'stumble', 'dynamic', 'additional', 'crumble', 'frivolous', 'rapid', 'diplomatic', 'preferable', 'situational', 'significant', 'definitive', 'unlocked', 'modest', 'doable', 'preliminary', 'unapproachable', 'ordinary', 'lavish', 'laughable', 'foreseeable', 'economic', 'justifiable', 'vocabulary', 'unannounced', 'ineffective', 'negotiable', 'unwilling', 'questionable', 'environmental', 'main', 'ulterior', 'unimportant', 'final', 'unforgettable', 'unofficial', 'scan', 'immoral', 'impressive', 'uphold', 'functional', 'fewer', 'accepted', 'comical', 'intentional', 'fabulous', 'excessive', 'tactic', 'fumble', 'racial', 'adjective', 'solitary', 'isolated', 'unfamiliar', 'logistical', 'controllable', 'problematic', 'unambiguous', 'interracial', 'rigid', 'advantageous', 'transsexual', 'iced', 'atypical', 'optimal', 'applicable', 'crucial', 'abnormal', 'achievable', 'cryptic', 'occasional', 'advanced', 'advisable', 'false', 'manual', 'unbiased', 'moral', 'unheard', 'aesthetic', 'integral', 'agreeable', 'prospective', 'hectic', 'unreliable', 'attainable', 'demographic', 'invasive', 'real', 'unintentional', 'volatile', 'unspoken', 'dubious', 'monetary', 'evasive', 'therapeutic', 'ramble', 'unbalanced', 'overwhelmed', 'unbearable', 'gradual', 'contagious', 'unlimited', 'external', 'golden', 'historical', 'unable', 'unwarranted', 'manageable', 'negligible', 'continuous', 'nonverbal', 'unprepared', 'residual', 'unnoticed', 'rhetorical', 'undue', 'domestic', 'unneeded', 'comparable', 'magnetic', 'hideous', 'fullest', 'unattached', 'automatic']\n",
            "['other']\n",
            "['difficult', 'hard']\n",
            "['easiest', 'best']\n",
            "['common']\n",
            "['ive']\n",
            "['easier']\n",
            "['disappointed', 'surprised']\n",
            "['enjoyable', 'acceptable', 'beneficial', 'unlikely', 'normal', 'unusual', 'special', 'understandable', 'useful', 'reasonable', 'effective', 'possible', 'valid', 'expensive', 'serious', 'risky', 'easy', 'healthy', 'unrealistic']\n",
            "['obvious', 'clear']\n",
            "['low']\n",
            "['similar']\n",
            "['comfortable', 'exclusive', 'satisfied', 'happy']\n",
            "['small']\n",
            "['least']\n",
            "['interested']\n",
            "['good', 'great']\n",
            "['initial']\n",
            "['inexpensive', 'arrive', 'wide', 'spanish', 'uni', 'italian', 'political', 'recreational', 'polish', 'central', 'upper', 'exotic', 'foreign', 'ethnic', 'latest', 'urban', 'slower', 'interactive', 'musical', 'olive', 'international', 'delicious', 'weekly', 'botanical', 'indian', 'oral', 'irish', 'nearest', 'northern', 'french', 'vegetarian', 'february', 'alcoholic']\n",
            "['compatible']\n",
            "['impossible']\n",
            "['second', 'third']\n",
            "['ready']\n",
            "['capable']\n",
            "['mutual']\n",
            "['different']\n",
            "['busy']\n",
            "['live']\n",
            "['personal']\n",
            "['physical']\n",
            "['free']\n",
            "['specific', 'particular']\n",
            "['romantic']\n",
            "['formal', 'neutral', 'memorable', 'cultural', 'limited', 'creative', 'open', 'familiar', 'broad', 'impersonal', 'solid', 'private', 'religious', 'productive', 'approachable', 'heavy', 'basic', 'enthusiastic', 'humorous', 'detailed', 'curious', 'spontaneous', 'optimistic', 'intellectual']\n",
            "['various', 'few']\n",
            "['smaller', 'large', 'larger']\n",
            "['current']\n",
            "['much']\n",
            "['local']\n",
            "['lower', 'higher']\n",
            "['important']\n",
            "['casual']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Exploring the conceptual biases from partition biased towards ts2, only printing the words in each cluster.\n",
        "'''\n",
        "print(len(cl2))\n",
        "for cluster in cl2:\n",
        "  print( [k['word'] for k in cluster] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku4p2fh6f-q7",
        "outputId": "4ec4c465-289b-4a76-af06-826461ab8e93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "['nasty', 'gross', 'puppy', 'sappy', 'grand', 'sudden', 'hilarious']\n",
            "['sensitive', 'powerful', 'dramatic', 'attentive', 'critical', 'generous']\n",
            "['social']\n",
            "['conscious']\n",
            "['due']\n",
            "['old']\n",
            "['inexperienced', 'oblivious']\n",
            "['underwear', 'bisexual', 'steady', 'black', 'rich', 'obese', 'modern', 'fetish', 'african', 'military', 'promiscuous', 'serial', 'unemployed']\n",
            "['entire', 'whole']\n",
            "['experienced']\n",
            "['overall', 'psychological', 'behavioral', 'severe', 'manifest', 'tiny', 'imaginary', 'inevitable', 'unrequited', 'former', 'internal', 'biological', 'interpersonal', 'ultimate']\n",
            "['sexual']\n",
            "['young']\n",
            "['full']\n",
            "['angry']\n",
            "['bigger']\n",
            "['related']\n",
            "['such']\n",
            "['horrible']\n",
            "['aware']\n",
            "['guilty']\n",
            "['unattractive']\n",
            "['respectable', 'abrasive', 'neurotic', 'obnoxious', 'egotistical', 'apologetic', 'misogynistic', 'courageous', 'antisocial', 'stereotypical', 'pretentious', 'unfaithful', 'charismatic', 'civil', 'competitive', 'honorable', 'expressive', 'exceptional', 'apprehensive', 'uptight', 'complex', 'humble', 'soft', 'visual', 'hypocritical', 'unpopular', 'offish', 'uncertain', 'likable', 'sympathetic', 'undesirable', 'callous', 'sensible', 'materialistic', 'identical', 'unprofessional', 'narcissistic', 'literal', 'ultra', 'skeptical', 'pragmatic', 'autistic', 'disabled', 'chivalrous', 'apathetic', 'irresponsible', 'agressive']\n",
            "['average']\n",
            "['rid']\n",
            "['poor']\n",
            "['miserable', 'unhappy']\n",
            "['alive']\n",
            "['total', 'complete']\n",
            "['responsible']\n",
            "['little']\n",
            "['same']\n",
            "['massive', 'huge']\n",
            "['pathetic', 'obsessive', 'stupid', 'naive', 'arrogant', 'pessimistic', 'cynical', 'insensitive', 'irrational', 'indecisive', 'uninterested', 'sarcastic', 'suspicious']\n",
            "['naked']\n",
            "['aggressive']\n",
            "['mysterious', 'assertive']\n",
            "['professional']\n",
            "['depressed']\n",
            "['abusive']\n",
            "['loose']\n",
            "['classic', 'typical']\n",
            "['financial']\n",
            "['safe']\n",
            "['homosexual', 'ouch', 'unfriended', 'lest', 'unapologetic', 'glorious', 'enable', 'heterosexual', 'dependable', 'argumentative', 'lustful', 'hippy', 'vicious', 'bearable', 'metaphorical', 'pedantic', 'psychotic', 'delighted', 'preppy', 'brazilian', 'nuclear', 'tic', 'induced', 'irritable', 'freudian', 'mechanical', 'ecstatic', 'unemotional', 'forgive', 'enigmatic', 'asynchronous', 'psychic', 'sociopathic', 'unmotivated', 'fixable', 'gullible', 'vietnamese', 'largest', 'ethic', 'sophisticated', 'unproductive', 'electric', 'extraordinary', 'devious', 'nibble', 'unkempt', 'poisonous', 'sloppy', 'factual', 'improbable', 'overdrive', 'formative', 'overprotective', 'invalid', 'unlovable', 'wisest', 'criminal', 'unattainable', 'corporate', 'diary', 'urbandictionary', 'archive', 'injured', 'customary', 'uncalled', 'upright', 'fictional', 'quickest', 'unmarried', 'idiotic', 'theoretical', 'pompous', 'mathematical', 'swedish', 'horrendous', 'literary', 'observational', 'melodramatic', 'concious', 'despicable', 'mystical', 'clinical', 'bubble', 'simultaneous', 'fashionable', 'facetious', 'infamous', 'unwritten', 'consensual', 'notable', 'perpetual', 'debatable', 'overzealous', 'eccentric', 'optional', 'gregarious', 'chaotic', 'educational', 'secondary', 'salvageable', 'unprotected', 'forgivable', 'unsatisfied', 'tactical', 'interchangeable', 'statistic', 'nonsensical', 'slouch', 'precarious', 'imaginable', 'behavioural', 'static', 'intact', 'nigh', 'invisible', 'unconventional', 'neurotypical', 'furious', 'libertarian', 'righteous', 'susceptible', 'sharp', 'tremendous', 'scottish', 'disastrous', 'infectious', 'unexperienced', 'dabble', 'mumble', 'unsolicited', 'anal', 'untrustworthy', 'unfavorable', 'explosive', 'fuckable', 'vaginal', 'chauvinistic', 'grammatical', 'regrettable', 'liable', 'spiritual', 'unsafe', 'uncontrollable', 'irresistible', 'palatable', 'envious', 'sustainable', 'energetic', 'commercial', 'lowest', 'precious', 'nest', 'dictionary', 'unfounded', 'radical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rZOyyRyBh8BU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}